{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYqkdlgQOCCqve1H7Zn20W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lzhkaya98/SSMGlobal/blob/main/Differential_SSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-1VPJMmFhXq"
      },
      "outputs": [],
      "source": [
        "#!pip install torch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as tf\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import xlrd\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "import pylab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#数据集加载\n",
        "sta_train , dyn_train, sigma_train, cos_train, rough_train, y1 , sta_test, dyn_test, sigma_test, cos_test, rough_test, y2 = load_data(str('/content/drive/My Drive/SMN-SDR.xls'))\n",
        "#静态数据集，动态数据集(5个时间步)，反向散射系数集、入射角集，地表粗糙度信息集\n",
        "\n",
        "#网络超参数设置\n",
        "#FNN\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(input_size)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.bn(x)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "#LSTM\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "#微分WCM模型\n",
        "#动态参数VC，静态参数C,C=A/B,VC=B*vegetation correlation coefficient\n",
        "def WCM(C, VC, sigma, cos_theta, rough):\n",
        "    gamma = torch.exp(-2 * VC / cos_theta)\n",
        "    sigma_veg = C * VC * cos_theta * (1 - gamma)\n",
        "    sigma_soil = (sigma - sigma_veg) / gamma\n",
        "    input = torch.cat([sigma_soil, rough], dim=1)\n",
        "    return input\n",
        "\n",
        "#散点图\n",
        "def scatter_plot_frequency(x, y):\n",
        "  xy = np.vstack([x,y])\n",
        "  z = gaussian_kde(xy)(xy)\n",
        "  # Sort the points by density, so that the densest points are plotted last\n",
        "  idx = z.argsort()\n",
        "  x, y, z = x[idx], y[idx], z[idx]\n",
        "  fig, ax = plt.subplots()\n",
        "  # 设置参考的1：1虚线参数\n",
        "  xxx = [0, 50]  #[0, 0.6]\n",
        "  yyy = [0, 50]\n",
        "  plt.plot(xxx, yyy, c='0', linewidth=1, linestyle=':', marker='.', alpha=0.3)  # 绘制虚线\n",
        "  plt.scatter(x, y, c=z, s=20, cmap='Spectral_r')\n",
        "  z=np.polyfit(x,y,1)\n",
        "  p=np.poly1d(z)\n",
        "  pylab.plot(x,p(x),\"r\")\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    dataset = data.TensorDataset(*data_arrays)\n",
        "    return data.DataLoader(dataset,batch_size,shuffle=True)\n",
        "\n",
        "#模型训练\n",
        "batch_size = 256 #256\n",
        "num_epochs = 6000  #6000\n",
        "data_iter = load_array((dyn_train,sta_train,sigma_train,cos_train,rough_train,y1), batch_size)\n",
        "\n",
        "model_C = Net(3,10,1)\n",
        "model_VC = LSTM(4,20,2,1)\n",
        "model_SM = Net(4,15,1)\n",
        "\n",
        "#定义损失函数和优化器\n",
        "criterion = nn.MSELoss()\n",
        "trainer1 = torch.optim.SGD(model_SM.parameters(),lr=0.001)\n",
        "trainer2 = torch.optim.SGD(model_VC.parameters(),lr=0.001)\n",
        "trainer3 = torch.optim.SGD(model_C.parameters(),lr=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for dyn,sta,sig,cost,rou,y in data_iter:\n",
        "        VC = model_VC(dyn)\n",
        "        C = model_C(sta)\n",
        "        input = WCM(C, VC, sig, cost, rou)\n",
        "        SM = model_SM(input)\n",
        "\n",
        "        loss = criterion(SM, y)\n",
        "#        print(loss)\n",
        "        model_SM.zero_grad()\n",
        "        model_VC.zero_grad()\n",
        "        model_C.zero_grad()\n",
        "        loss.backward()\n",
        "        trainer1.step()\n",
        "        trainer2.step()\n",
        "        trainer3.step()\n",
        "#    print(f'epoch {epoch+1}')\n",
        "\n",
        "#模型保存\n",
        "torch.save(model_C.state_dict(), str('/content/drive/My Drive/model_C.pth'))\n",
        "torch.save(model_VC.state_dict(), str('/content/drive/My Drive/model_VC.pth'))\n",
        "torch.save(model_SM.state_dict(), str('/content/drive/My Drive/model_SM.pth'))\n",
        "\n",
        "#模型加载 需实例化模型model_C = Net(2,5,1)\n",
        "#model_C.load_state_dict(torch.load(str('/content/drive/My Drive/model_C.pth')))\n",
        "#model_VC.load_state_dict(torch.load(str('/content/drive/My Drive/model_VC.pth')))\n",
        "#model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/model_SM.pth')))\n",
        "#model_C.eval();model_VC.eval();model_SM.eval()\n",
        "\n",
        "#模型测试\n",
        "VC_test = model_VC(dyn_test)\n",
        "C_test = model_C(sta_test)\n",
        "input_test = WCM(C_test, VC_test, sigma_test, cos_test, rough_test)\n",
        "SM_test = model_SM(input_test)\n",
        "loss = criterion(SM_test, y2)\n",
        "print(loss)\n",
        "\n",
        "#模型输出评估\n",
        "#\"\"\"\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "Y_test = y2.numpy()\n",
        "Y_pred = SM_test.detach().numpy()\n",
        "#print(Y_test)\n",
        "#print(Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "ResidualSquare = (Y_pred - Y_test) ** 2\n",
        "MSE = np.mean(ResidualSquare)\n",
        "bias = np.mean(Y_pred - Y_test)\n",
        "RMSE = np.sqrt(MSE)\n",
        "ubRMSE = np.sqrt(RMSE ** 2 - bias ** 2)\n",
        "print(f'R2={r2}')\n",
        "print(f'bias={bias}')\n",
        "print(f'RMSE={RMSE}')\n",
        "print(f'ubRMSE={ubRMSE}')\n",
        "print(\"R P\", pearsonr(Y_pred[:,0], Y_test[:,0]))\n",
        "scatter_plot_frequency(Y_test[:,0],Y_pred[:,0])  #生成散点图\n",
        "#\"\"\""
      ]
    }
  ]
}