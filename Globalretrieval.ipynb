{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lzhkaya98/SSMGlobal/blob/main/Globalretrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce4gexc4FaUa"
      },
      "outputs": [],
      "source": [
        "###模型训练###\n",
        "#!pip install xlrd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as tf\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import xlrd\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "import pylab\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#数据集加载\n",
        "def load_data(StartPo,EndPo,TestProportion,FeatureNum,Shuffle,FilePath):         #样本起始行数，结束行数，测试集占总样本集比重,特征数，是否打乱样本集     #如果Testproportion为0或1就训练集=测试集\n",
        "    #打开excel文件\n",
        "    workbook = xlrd.open_workbook(str(FilePath))       #excel路径\n",
        "    sheet = workbook.sheet_by_name('sheet1')             #sheet表\n",
        "    Sample = []#总样本集\n",
        "    train = []#训练集\n",
        "    test = []#测试集\n",
        "    TestSetSphere = (EndPo-StartPo+1)*TestProportion  #测试集数目\n",
        "    TestSetSphere = int(TestSetSphere)#测试集数目\n",
        "    #获取全部样本集并打乱顺序\n",
        "    for loadi in range(StartPo-1,EndPo):\n",
        "        RowSample = sheet.row_values(loadi)\n",
        "        Sample.append(RowSample)\n",
        "    if Shuffle == 1:  #是否打乱样本集\n",
        "        random.shuffle(Sample)  #如果shuffle=1，打乱样本集\n",
        "    #如果Testproportion为0就训练集=测试集\n",
        "    if TestProportion == 0 or TestProportion == 1:\n",
        "        TrainSet = np.array(Sample)          #变换为array\n",
        "        TestSet = np.array(Sample)\n",
        "        TrainSet = torch.Tensor(TrainSet)\n",
        "        TestSet = torch.Tensor(TestSet)\n",
        "    else:\n",
        "        #设置训练集\n",
        "        for loadtraina in Sample[:(EndPo-TestSetSphere)]:\n",
        "            GetTrainValue = loadtraina\n",
        "            train.append(GetTrainValue)\n",
        "        #设置测试集\n",
        "        for loadtesta in range(-TestSetSphere-1,-1):\n",
        "            GetTestValue = Sample[loadtesta]\n",
        "            test.append(GetTestValue)\n",
        "        #变换样本集\n",
        "        TrainSet = np.array(train)                  #变换为array\n",
        "        TestSet = np.array(test)\n",
        "        TrainSet = torch.Tensor(TrainSet)\n",
        "        TestSet = torch.Tensor(TestSet)\n",
        "\n",
        "\n",
        "   #分割特征与目标变量\n",
        "    x1 , y1 = TrainSet[:,:FeatureNum] , TrainSet[:,-1]\n",
        "    Tb_train = x1[:,0] ; LST_train = x1[:,1] ; dyn_train = x1[:,2:5] ; sta_train = x1[:,2:5] ; dic_train = x1[:,10:FeatureNum-1]\n",
        "    x2 , y2 = TestSet[:,:FeatureNum] , TestSet[:,-1]\n",
        "    Tb_test = x2[:,0] ; LST_test = x2[:,1] ; dyn_test = x2[:,2:5] ; sta_test = x2[:,2:5] ; dic_test = x2[:,10:FeatureNum-1]\n",
        "    return sta_train , dyn_train, torch.unsqueeze(Tb_train,dim=1), torch.unsqueeze(LST_train,dim=1), dic_train, torch.unsqueeze(y1,dim=1) , sta_test, dyn_test, torch.unsqueeze(Tb_test,dim=1), torch.unsqueeze(LST_test,dim=1), dic_test, torch.unsqueeze(y2,dim=1)\n",
        "\n",
        "sta_train , dyn_train, Tb_train, LST_train, dic_train, y1 , sta_test, dyn_test, Tb_test, LST_test, dic_test, y2 = load_data(2,65536,0.2,14,1,str('/content/drive/My Drive/train_global.xls'))\n",
        "#网络超参数设置\n",
        "#具有两个隐藏层的FNN\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(input_size)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc5 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.bn(x)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    dataset = data.TensorDataset(*data_arrays)\n",
        "    return data.DataLoader(dataset,batch_size,shuffle=True)\n",
        "\n",
        "\n",
        "#微分WCM模型\n",
        "#动态参数VC，静态参数C\n",
        "def SCA(w, tau, Tb, LST, dic):\n",
        "    gamma = torch.exp(-tau / 0.766)    #cos40°=0.766\n",
        "    sigma_veg = Tb - LST * ((1-w)*(1-gamma)+gamma)\n",
        "    sigma_soil = LST * gamma * ((1-w)*(1-gamma)-1)\n",
        "    r = sigma_veg / sigma_soil\n",
        "    input = torch.cat([r, dic], dim=1)\n",
        "    return input\n",
        "\n",
        "#散点图\n",
        "def scatter_plot_frequency(x, y):\n",
        "  xy = np.vstack([x,y])\n",
        "  z = gaussian_kde(xy)(xy)\n",
        "  # Sort the points by density, so that the densest points are plotted last\n",
        "  idx = z.argsort()\n",
        "  x, y, z = x[idx], y[idx], z[idx]\n",
        "  fig, ax = plt.subplots()\n",
        "  # 设置参考的1：1虚线参数\n",
        "  xxx = [0, 0.6]  #[0, 0.6] 40\n",
        "  yyy = [0, 0.6]\n",
        "  plt.plot(xxx, yyy, c='0', linewidth=1, linestyle=':', marker='.', alpha=0.3)  # 绘制虚线\n",
        "  plt.scatter(x, y, c=z, s=20, cmap='Spectral_r')\n",
        "  z=np.polyfit(x,y,1)\n",
        "  p=np.poly1d(z)\n",
        "  pylab.plot(x,p(x),\"r\")\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "#模型训练\n",
        "batch_size = 128 #16,32,64...\n",
        "num_epochs = 3000  #1000,2000...\n",
        "data_iter = load_array((sta_train , dyn_train, Tb_train, LST_train, dic_train, y1), batch_size)\n",
        "\n",
        "model_w = Net(3,5,1)   #5 10 1\n",
        "model_tau = Net(3,5,1)   #8 10 1\n",
        "model_SM = Net(4,5,1)   #10 10 1\n",
        "#定义损失函数和优化器\n",
        "criterion = nn.L1Loss()\n",
        "trainer1 = torch.optim.SGD(model_SM.parameters(),lr=0.01)\n",
        "trainer2 = torch.optim.SGD(model_tau.parameters(),lr=0.01)\n",
        "trainer3 = torch.optim.SGD(model_w.parameters(),lr=0.01)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for sta,dyn,Tb,LST,dic,y in data_iter:\n",
        "        tau = model_tau(dyn)\n",
        "        w = model_w(sta) #sta\n",
        "        input = SCA(w, tau, Tb, LST, dic)\n",
        "        SM = model_SM(input)\n",
        "\n",
        "        loss = criterion(SM, y)\n",
        "#        print(loss)\n",
        "        model_SM.zero_grad()\n",
        "        model_tau.zero_grad()\n",
        "        model_w.zero_grad()\n",
        "        loss.backward()\n",
        "        trainer1.step()\n",
        "        trainer2.step()\n",
        "        trainer3.step()\n",
        "#    print(f'epoch {epoch+1}')\n",
        "\n",
        "#模型保存\n",
        "torch.save(model_w.state_dict(), str('/content/drive/My Drive/model_w_global4.pth'))\n",
        "torch.save(model_tau.state_dict(), str('/content/drive/My Drive/model_tau_global4.pth'))\n",
        "torch.save(model_SM.state_dict(), str('/content/drive/My Drive/model_SM_global4.pth'))\n",
        "\n",
        "\n",
        "#模型测试\n",
        "tau_test = model_tau(dyn_test)\n",
        "w_test = model_w(sta_test)  #dyn_test\n",
        "input_test = SCA(w_test, tau_test, Tb_test, LST_test, dic_test)\n",
        "SM_test = model_SM(input_test)\n",
        "loss = criterion(SM_test, y2)\n",
        "print(loss)\n",
        "\n",
        "#模型输出评估\n",
        "#\"\"\"\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "Y_test = y2.numpy()\n",
        "Y_pred = SM_test.detach().numpy()\n",
        "#print(Y_test)\n",
        "#print(Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "ResidualSquare = (Y_pred - Y_test) ** 2\n",
        "MSE = np.mean(ResidualSquare)\n",
        "bias = np.mean(Y_pred - Y_test)\n",
        "RMSE = np.sqrt(MSE)\n",
        "ubRMSE = np.sqrt(RMSE ** 2 - bias ** 2)\n",
        "print(f'R2={r2}')\n",
        "print(f'bias={bias}')\n",
        "print(f'RMSE={RMSE}')\n",
        "print(f'ubRMSE={ubRMSE}')\n",
        "print(\"R P\", pearsonr(Y_pred[:,0], Y_test[:,0]))\n",
        "scatter_plot_frequency(Y_test[:,0],Y_pred[:,0])  #生成散点图\n",
        "#\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as tf\n",
        "from torch.utils import data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from datetime import date\n",
        "import time\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-whulzh98')\n",
        "from time import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "###########################################################模型选择##############################################################################\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(input_size)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc5 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.bn(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "#SCA-V模型\n",
        "def SCA(w, tau, Tb, LST, dic):\n",
        "    gamma = torch.exp(-tau / 0.766)    #cos40°=0.766\n",
        "    sigma_veg = Tb - LST * ((1-w)*(1-gamma)+gamma)\n",
        "    sigma_soil = LST * gamma * ((1-w)*(1-gamma)-1)\n",
        "    r = sigma_veg / sigma_soil\n",
        "    input = torch.cat([r, dic], dim=1)\n",
        "    return input\n",
        "#模型默认为5,8,10，relu\n",
        "model_w = Net(5,10,1)   #5 10 1\n",
        "model_tau = Net(8,10,1)   #8 10 1\n",
        "model_SM = Net(10,10,1)   #10 10 1\n",
        "\n",
        "###########################################################数据获取##############################################################################\n",
        "timerange = ee.Filter.date('2018-01-1', '2018-12-31')\n",
        "def auxiliarydate_load(lonn,latt,scaled):\n",
        "  pt= ee.Geometry.Point([lonn,latt])\n",
        "\n",
        "  dataset1 = ee.Image('COPERNICUS/Landcover/100m/Proba-V-C3/Global/2019')\n",
        "  barecover = dataset1.select('bare-coverfraction')\n",
        "  ft1 = barecover.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  grasscover = dataset1.select('grass-coverfraction')\n",
        "  ft2 = grasscover.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  cropscover = dataset1.select('crops-coverfraction')\n",
        "  ft3 = cropscover.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  shrubcover = dataset1.select('shrub-coverfraction')\n",
        "  ft4 = shrubcover.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  treecover = dataset1.select('tree-coverfraction')\n",
        "  ft5 = treecover.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  Bare = ft1.getInfo().get('features')[0]['properties']['first']/100\n",
        "  Grass = ft2.getInfo().get('features')[0]['properties']['first']/100\n",
        "  Crops = ft3.getInfo().get('features')[0]['properties']['first']/100\n",
        "  Shrub = ft4.getInfo().get('features')[0]['properties']['first']/100\n",
        "  Tree = ft5.getInfo().get('features')[0]['properties']['first']/100\n",
        "\n",
        "  dataset2 = ee.Image(\"OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02\").select('b0')\n",
        "  dataset3 = ee.Image(\"OpenLandMap/SOL/SOL_SAND-WFRACTION_USDA-3A1A1A_M/v02\").select('b0')\n",
        "  dataset4 = ee.Image(\"OpenLandMap/SOL/SOL_BULKDENS-FINEEARTH_USDA-4A1H_M/v02\").select('b0')\n",
        "\n",
        "  ft6=dataset2.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  ft7=dataset3.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  ft8=dataset4.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "\n",
        "  Clay = ft6.getInfo().get('features')[0]['properties']['first']/100\n",
        "  Sand = ft7.getInfo().get('features')[0]['properties']['first']/100\n",
        "  Bulk = ft8.getInfo().get('features')[0]['properties']['first']/100\n",
        "\n",
        "  dataset5 = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
        "  slope1 = ee.Terrain.slope(dataset5)\n",
        "  ft9 = slope1.reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "  Slope = ft9.getInfo().get('features')[0]['properties']['first']\n",
        "\n",
        "  return Bare,Grass,Crops,Shrub,Tree,Clay,Sand,Bulk,Slope\n",
        "\n",
        "def modisload(lonn,latt,year,month,day,scaled):\n",
        "\n",
        "  def dataload(dataset):\n",
        "    M = dataset.filter(timerange)\n",
        "    pt= ee.Geometry.Point([lonn,latt])\n",
        "    begin = datetime.date(year,month,day) #开始时间\n",
        "    d = begin\n",
        "    delta = datetime.timedelta(days=3)\n",
        "    oneDate=d.strftime(\"%Y-%m-%d\")\n",
        "    dd=d+delta\n",
        "    oneDate_next=dd.strftime(\"%Y-%m-%d\")\n",
        "    M_Day=M.filterDate(oneDate,oneDate_next).filterBounds(pt)\n",
        "    ft1=M_Day.first().reduceRegions(pt, ee.Reducer.first(),scaled)\n",
        "    data1=ft1.getInfo().get('features')[0]['properties'].get('first',None)\n",
        "\n",
        "    return data1\n",
        "\n",
        "  dataset1 = ee.ImageCollection('MODIS/MYD09GA_006_NDVI').select('NDVI')\n",
        "  dataset2 = ee.ImageCollection('MODIS/MYD09GA_006_NDWI').select('NDWI')\n",
        "  dataset3 = ee.ImageCollection('MODIS/MOD09GA_006_EVI').select('EVI')\n",
        "  dataset4 = ee.ImageCollection('MODIS/061/MOD11A1').select('LST_Day_1km')\n",
        "  dataset5 = ee.ImageCollection('NASA/SMAP/SPL3SMP_E/005').select('tb_v_corrected_am')\n",
        "\n",
        "  NDVI = dataload(dataset1)\n",
        "  NDWI = dataload(dataset2)\n",
        "  EVI = dataload(dataset3)\n",
        "  LST = dataload(dataset4)*0.02\n",
        "  Tb = dataload(dataset5)\n",
        "\n",
        "  return NDVI,NDWI,EVI,LST,Tb\n",
        "\n",
        "###########################################################加载############################################################################\n",
        "###输入时间与经纬度信息、分辨率信息\n",
        "year = int(input(\"请输入年份：\"))\n",
        "month = int(input(\"请输入月份：\"))\n",
        "day = int(input(\"请输入日期：\"))\n",
        "lonn = float(input(\"请输入经度(°)：\"))\n",
        "latt = float(input(\"请输入纬度(°)：\"))\n",
        "scaled1 = int(input(\"请输入分辨率(m)：\"))\n",
        "#year = 2018\n",
        "#month = 6\n",
        "#day = 17\n",
        "#lonn = -100\n",
        "#latt = 35\n",
        "#scale = 500\n",
        "Bare,Grass,Crops,Shrub,Tree,Clay,Sand,Bulk,Slope = auxiliarydate_load(lonn,latt,scaled1)\n",
        "NDVI,NDWI,EVI,LST,Tb = modisload(lonn,latt,year,month,day,scaled1)\n",
        "\n",
        "##############加载选择训练模型\n",
        "m = int(input(\"请选择用于反演的模型：1.全球反演模型;2.分区域反演模型;3.分地表覆盖类型反演模型\"))\n",
        "if m == 1:\n",
        "  model_w.load_state_dict(torch.load(str('/content/drive/My Drive/model_w_global.pth'),weights_only=True))\n",
        "  model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/model_tau_global.pth'),weights_only=True))\n",
        "  model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/model_SM_global.pth'),weights_only=True))\n",
        "  model_w.eval();model_tau.eval();model_SM.eval()\n",
        "if m == 2:\n",
        "  if (latt >= 25 and latt <= 50) and (lonn >= -130 and lonn <= -70):\n",
        "      model_w.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_w_CONUS.pth'),weights_only=True))\n",
        "      model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_tau_CONUS.pth'),weights_only=True))\n",
        "      model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_SM_CONUS.pth'),weights_only=True))\n",
        "      model_w.eval();model_tau.eval();model_SM.eval()\n",
        "  else:\n",
        "      model_w.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_w_Other.pth'),weights_only=True))\n",
        "      model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_tau_Other.pth'),weights_only=True))\n",
        "      model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_SM_Other.pth'),weights_only=True))\n",
        "      model_w.eval();model_tau.eval();model_SM.eval()\n",
        "if m ==3:\n",
        "  if Grass >= 0.5:\n",
        "      model_w.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_w_Grass.pth'),weights_only=True))\n",
        "      model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_tau_Grass.pth'),weights_only=True))\n",
        "      model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_SM_Grass.pth'),weights_only=True))\n",
        "      model_w.eval();model_tau.eval();model_SM.eval()\n",
        "  elif Crops >= 0.5:\n",
        "      model_w.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_w_Crops.pth'),weights_only=True))\n",
        "      model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_tau_Crops.pth'),weights_only=True))\n",
        "      model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_SM_Crops.pth'),weights_only=True))\n",
        "      model_w.eval();model_tau.eval();model_SM.eval()\n",
        "  elif Tree >= 0.5:\n",
        "      model_w.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_w_Tree.pth'),weights_only=True))\n",
        "      model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_tau_Tree.pth'),weights_only=True))\n",
        "      model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/Global/model_SM_Tree.pth'),weights_only=True))\n",
        "      model_w.eval();model_tau.eval();model_SM.eval()\n",
        "  else:\n",
        "      model_w.load_state_dict(torch.load(str('/content/drive/My Drive/model_w_global.pth'),weights_only=True))\n",
        "      model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/model_tau_global.pth'),weights_only=True))\n",
        "      model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/model_SM_global.pth'),weights_only=True))\n",
        "      model_w.eval();model_tau.eval();model_SM.eval()\n",
        "####################################################反演####################################################################################\n",
        "start = time()\n",
        "\n",
        "if np.isnan(Tb):\n",
        "  Tb = 300\n",
        "if np.isnan(LST):\n",
        "  LST = 300\n",
        "Tb1 = torch.Tensor([Tb])\n",
        "LST1 = torch.Tensor([LST])\n",
        "sta = torch.cat([torch.Tensor([Grass]), torch.Tensor([Bare]), torch.Tensor([Crops]), torch.Tensor([Shrub]), torch.Tensor([Tree])], dim=0).reshape(1,-1)\n",
        "dyn = torch.cat([torch.Tensor([NDVI]), torch.Tensor([NDWI]), torch.Tensor([EVI]), torch.Tensor([Grass]), torch.Tensor([Bare]), torch.Tensor([Crops]), torch.Tensor([Shrub]), torch.Tensor([Tree])], dim=0).reshape(1,-1)\n",
        "dic = torch.cat([torch.Tensor([Grass]), torch.Tensor([Bare]), torch.Tensor([Crops]), torch.Tensor([Shrub]), torch.Tensor([Tree]), torch.Tensor([Clay]), torch.Tensor([Sand]), torch.Tensor([Bulk]),  torch.Tensor([Slope])], dim=0).reshape(1,-1)\n",
        "print(dyn)\n",
        "test_data=[NDVI,NDWI,EVI,LST,Tb,Bare,Grass,Crops,Shrub,Tree,Clay,Sand,Bulk,Slope]\n",
        "if np.isnan(test_data).any():\n",
        "  SM=np.nan\n",
        "else:\n",
        "  tau = model_tau(dyn)\n",
        "  w = model_w(sta)\n",
        "  input_test = SCA(w, tau, Tb1, LST1, dic)\n",
        "  SM_test = model_SM(input_test)\n",
        "  SM = SM_test.detach().numpy()[0,0]\n",
        "print(SM)\n",
        "\n",
        "end = time()\n",
        "\n",
        "print(\"time: \" + str(end - start) + \" sec\")\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DyQmXFD8187N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd89a1b-d09c-48ad-8252-ebb180972121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "请输入年份：2018\n",
            "请输入月份：6\n",
            "请输入日期：17\n",
            "请输入经度(°)：-100\n",
            "请输入纬度(°)：35\n",
            "请输入分辨率(m)：500\n",
            "请选择用于反演的模型：1.全球反演模型;2.分区域反演模型;3.分地表覆盖类型反演模型1\n",
            "tensor([[ 0.1745, -0.0057,  0.3135,  0.5200,  0.0400,  0.1300,  0.1600,  0.1600]])\n",
            "0.037006922\n",
            "time: 0.11550116539001465 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as tf\n",
        "from torch.utils import data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from datetime import date\n",
        "import time\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-whulzh98')\n",
        "from time import time\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "###########################################################读取模型##############################################################################\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(input_size)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc5 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.bn(x)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "#SCA-V模型\n",
        "def SCA(w, tau, Tb, LST, dic):\n",
        "    gamma = torch.exp(-tau / 0.766)    #cos40°=0.766\n",
        "    sigma_veg = Tb - LST * ((1-w)*(1-gamma)+gamma)\n",
        "    sigma_soil = LST * gamma * ((1-w)*(1-gamma)-1)\n",
        "    r = sigma_veg / sigma_soil\n",
        "    input = torch.cat([r, dic], dim=1)\n",
        "    return input\n",
        "\n",
        "model_w = Net(3,5,1)   #8 10 1\n",
        "model_tau = Net(3,5,1)   #8 10 1\n",
        "model_SM = Net(4,5,1)   #4 5 1\n",
        "\n",
        "#模型加载\n",
        "model_w.load_state_dict(torch.load(str('/content/drive/My Drive/model_w_global4.pth'),weights_only=True))\n",
        "model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/model_tau_global4.pth'),weights_only=True))\n",
        "model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/model_SM_global4.pth'),weights_only=True))\n",
        "model_w.eval();model_tau.eval();model_SM.eval()\n",
        "###########################################################数据获取##############################################################################\n",
        "\n",
        "def auxiliarydate_load(roi):\n",
        "  #加载 信息图像\n",
        "  dataset1 = ee.Image(\"OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02\").select('b0').unmask(0)\n",
        "  dataset1 = dataset1.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  print(dataset1.getInfo())\n",
        "  ft1 = dataset1.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)   #1000m分辨率\n",
        "  Clay = np.array(ee.Array(ft1.get('b0')).getInfo()).reshape(-1,1)/100\n",
        "\n",
        "  dataset2 = ee.Image(\"OpenLandMap/SOL/SOL_SAND-WFRACTION_USDA-3A1A1A_M/v02\").select('b0').unmask(0)\n",
        "  dataset2 = dataset2.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  ft2 = dataset2.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)   #1000m分辨率\n",
        "  Sand = np.array(ee.Array(ft2.get('b0')).getInfo()).reshape(-1,1)/100\n",
        "\n",
        "  dataset3 = ee.Image(\"OpenLandMap/SOL/SOL_BULKDENS-FINEEARTH_USDA-4A1H_M/v02\").select('b0').unmask(0)\n",
        "  dataset3 = dataset3.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  ft3 = dataset3.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)   #1000m分辨率\n",
        "  Bulk = np.array(ee.Array(ft3.get('b0')).getInfo()).reshape(-1,1)/100\n",
        "\n",
        "  dataset4 = ee.Image('USGS/SRTMGL1_003').select('elevation').unmask(0)\n",
        "  dataset4 = dataset4.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  dataset4 = dataset4.addBands(ee.Image.pixelLonLat())\n",
        "  ft4 = dataset4.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)   #1000m分辨率\n",
        "  lat = np.array(ee.Array(ft4.get('latitude')).getInfo())\n",
        "  lon = np.array(ee.Array(ft4.get('longitude')).getInfo())\n",
        "\n",
        "  return lat,lon,Clay,Sand,Bulk\n",
        "\n",
        "def modisload(roi,year,month,day):\n",
        "\n",
        "  begin = datetime.date(year,month,day) #开始时间\n",
        "  d = begin\n",
        "  delta = datetime.timedelta(days=30)\n",
        "  oneDate=d.strftime(\"%Y-%m-%d\")\n",
        "  dd=d+delta\n",
        "  oneDate_next=dd.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  dataset1 = ee.ImageCollection('MODIS/MYD09GA_006_NDVI').filterBounds(roi).filterDate(oneDate,oneDate_next).select('NDVI').mean().unmask(0)\n",
        "  dataset1 = dataset1.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  ft1 = dataset1.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)  #1000m分辨率\n",
        "  NDVI = np.array(ee.Array(ft1.get('NDVI')).getInfo()).reshape(-1,1)\n",
        "\n",
        "  dataset2 = ee.ImageCollection('MODIS/MYD09GA_006_NDWI').filterBounds(roi).filterDate(oneDate,oneDate_next).select('NDWI').mean().unmask(0)\n",
        "  dataset2 = dataset2.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  ft2 = dataset2.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)  #1000m分辨率\n",
        "  NDWI = np.array(ee.Array(ft2.get('NDWI')).getInfo()).reshape(-1,1)\n",
        "\n",
        "  dataset3 = ee.ImageCollection('MODIS/061/MOD11A1').filterBounds(roi).filterDate(oneDate,oneDate_next).select('LST_Day_1km').mean().unmask(0)\n",
        "  dataset3 = dataset3.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  ft3 = dataset3.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)  #1000m分辨率\n",
        "  LST = np.array(ee.Array(ft3.get('LST_Day_1km')).getInfo()).reshape(-1,1)*0.02\n",
        "\n",
        "  dataset4 = ee.ImageCollection('NASA/SMAP/SPL3SMP_E/005').filterBounds(roi).filterDate(oneDate,oneDate_next).select('tb_v_corrected_am').mean().unmask(0)\n",
        "  dataset4 = dataset4.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  ft4 = dataset4.reduceRegion(ee.Reducer.toList(),roi,scaled)  #500m分辨率\n",
        "  Tb = np.array(ee.Array(ft4.get('tb_v_corrected_am')).getInfo()).reshape(-1,1)\n",
        "\n",
        "  dataset5 = ee.ImageCollection('MODIS/MOD09GA_006_EVI').filterBounds(roi).filterDate(oneDate,oneDate_next).select('EVI').mean().unmask(0)\n",
        "  dataset5 = dataset5.reproject(crs='EPSG:4326',scale=scaled).clip(roi)\n",
        "  ft5 = dataset5.reduceRegion(ee.Reducer.toList(),roi,scaled,maxPixels=1e13)  #1000m分辨率\n",
        "  EVI = np.array(ee.Array(ft5.get('EVI')).getInfo()).reshape(-1,1)\n",
        "\n",
        "  return NDVI,NDWI,LST,EVI,Tb\n",
        "\n",
        "##########################################################图像转换#######################################################################\n",
        "def toArray(lat,lon,SM):\n",
        "  uniqueLats,lat_ind = np.unique(lat,return_inverse=True)\n",
        "  uniqueLons,lon_ind = np.unique(lon,return_inverse=True)\n",
        "  ncols = len(uniqueLons)\n",
        "  nrows = len(uniqueLats)\n",
        "  print(ncols,nrows)\n",
        "  arr = np.zeros([nrows,ncols])\n",
        "\n",
        "  for x in range(0,len(SM)):\n",
        "    arr[nrows-1-lat_ind[x],lon_ind[x]]=SM[x]\n",
        "  return arr\n",
        "\n",
        "###########################################################反演############################################################################\n",
        "#中国经纬度范围(73.55, 18.16, 135.08, 53.55)\n",
        "#世界经纬度范围(-180,-57,180,84)\n",
        "roi = ee.Geometry.Rectangle(73.55, 18.16, 135.08, 53.55).bounds()  #注意经纬度差不能超过90°\n",
        "#roi = ee.Geometry.Polygon([[[0, 84],[0, -57],[179, -57],[179, 84]]]).bounds() #注意坐标应按照顺时针，经度不能为180\n",
        "#roi = ee.Geometry.Rectangle(-45, -45,45, 45).bounds()   #注意经纬度差不能超过90°\n",
        "\n",
        "year = 2018\n",
        "month = 7\n",
        "day = 1\n",
        "\n",
        "scaled = 9000\n",
        "\n",
        "start = time()\n",
        "\n",
        "lat,lon,Clay,Sand,Bulk = auxiliarydate_load(roi)\n",
        "NDVI,NDWI,LST,EVI,Tb = modisload(roi,year,month,day)\n",
        "Tb[np.isnan(Tb)]=300\n",
        "LST[np.isnan(LST)]=300\n",
        "NDVI[np.isnan(NDVI)]=0\n",
        "NDWI[np.isnan(NDWI)]=0\n",
        "EVI[np.isnan(EVI)]=0\n",
        "Clay[np.isnan(Clay)]=0\n",
        "Sand[np.isnan(Sand)]=0\n",
        "Bulk[np.isnan(Bulk)]=0\n",
        "\n",
        "end = time()\n",
        "\n",
        "print(\"time: \" + str(end - start) + \" sec\")\n",
        "\n",
        "start = time()\n",
        "\n",
        "Tb1 = torch.Tensor(Tb)\n",
        "LST1 = torch.Tensor(LST)\n",
        "sta = torch.cat([torch.Tensor(NDVI), torch.Tensor(NDWI), torch.Tensor(EVI)], dim=1)\n",
        "dyn = torch.cat([torch.Tensor(NDVI), torch.Tensor(NDWI), torch.Tensor(EVI)], dim=1)\n",
        "dic = torch.cat([torch.Tensor(Clay), torch.Tensor(Sand), torch.Tensor(Bulk)], dim=1)\n",
        "\n",
        "del Tb,LST,NDWI,EVI,Clay,Bulk\n",
        "\n",
        "tau = model_tau(dyn)\n",
        "w = model_w(sta)\n",
        "del sta,dyn\n",
        "del model_w,model_tau\n",
        "input_test = SCA(w, tau, Tb1, LST1, dic)\n",
        "del w,tau,Tb1,LST1,dic\n",
        "SM_test = model_SM(input_test)\n",
        "del input_test\n",
        "del model_SM\n",
        "torch.cuda.empty_cache()\n",
        "SM = SM_test.detach().numpy()\n",
        "\n",
        "end = time()\n",
        "\n",
        "print(\"time: \" + str(end - start) + \" sec\")\n",
        "\n",
        "start = time()\n",
        "\n",
        "SM[Sand == 0]=0\n",
        "#SM[NDVI <= 0]=0\n",
        "\n",
        "SM1 = toArray(lat,lon,SM)\n",
        "SM_img=Image.fromarray(SM1)\n",
        "SM_img.save('/content/drive/My Drive/Global.tif')\n",
        "\n",
        "end = time()\n",
        "\n",
        "print(\"time: \" + str(end - start) + \" sec\")"
      ],
      "metadata": {
        "id": "6XmxYkFZx6ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4185f013-59a0-4394-e051-3b49f47bb52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "{'type': 'Image', 'bands': [{'id': 'b0', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 255}, 'dimensions': [762, 489], 'origin': [909, -713], 'crs': 'EPSG:4326', 'crs_transform': [0.08084837557075693, 0, 0, 0, -0.08084837557075693, 0]}], 'version': 1651671975432479, 'id': 'OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02', 'properties': {'system:footprint': {'geodesic': False, 'type': 'Polygon', 'coordinates': [[[73.55, 18.159999999999975], [135.08, 18.159999999999975], [135.08, 57.59798889543937], [73.55, 57.59798889543937], [73.55, 18.159999999999975]]]}, 'system:time_start': -631152000000, 'system:description': 'Based on machine learning predictions from global compilation of soil profiles and samples.\\n<br>\\n<a href=\"https://github.com/Envirometrix/LandGISmaps#soil-properties-and-classes\"> description </a>', 'system:time_end': 1514678400000, 'system:asset_size': 10811502500}}\n",
            "time: 70.83998966217041 sec\n",
            "time: 0.4341738224029541 sec\n",
            "761 487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2c4c8296d0bb>:132: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  arr[nrows-1-lat_ind[x],lon_ind[x]]=SM[x]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 0.7895209789276123 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jke93xdeH3ES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9774a9bb-61c1-4e3a-e6b5-69cd38dbd41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "4453\n",
            "1745\n"
          ]
        }
      ],
      "source": [
        "###反演图生产###\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as tf\n",
        "from torch.utils import data\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(input_size)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc5 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.bn(x)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "def SCA(w, tau, Tb, LST, dic):\n",
        "    gamma = torch.exp(-tau / 0.766)    #cos40°=0.766\n",
        "    sigma_veg = Tb - LST * ((1-w)*(1-gamma)+gamma)\n",
        "    sigma_soil = LST * gamma * ((1-w)*(1-gamma)-1)\n",
        "    r = sigma_veg / sigma_soil\n",
        "    input = torch.cat([r, dic], dim=1)\n",
        "    return input\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  dataset1=gdal.Open(r'/content/drive/My Drive/Global/Tb10Img9km.tif')\n",
        "  dataset2=gdal.Open(r'/content/drive/My Drive/Global/LST10Img9km.tif')\n",
        "  dataset3=gdal.Open(r'/content/drive/My Drive/Global/NDVI10Img9km.tif')\n",
        "  dataset4=gdal.Open(r'/content/drive/My Drive/Global/NDWI10Img9km.tif')\n",
        "  dataset5=gdal.Open(r'/content/drive/My Drive/Global/EVI10Img9km.tif')\n",
        "  dataset6=gdal.Open(r'/content/drive/My Drive/Global/grassImg9km.tif')\n",
        "  dataset7=gdal.Open(r'/content/drive/My Drive/Global/bareImg9km.tif')\n",
        "  dataset8=gdal.Open(r'/content/drive/My Drive/Global/cropsImg9km.tif')\n",
        "  dataset9=gdal.Open(r'/content/drive/My Drive/Global/shrubImg9km.tif')\n",
        "  dataset10=gdal.Open(r'/content/drive/My Drive/Global/treeImg9km.tif')\n",
        "  dataset11=gdal.Open(r'/content/drive/My Drive/Global/clayImg9km.tif')\n",
        "  dataset12=gdal.Open(r'/content/drive/My Drive/Global/sandImg9km.tif')\n",
        "  dataset13=gdal.Open(r'/content/drive/My Drive/Global/bulkImg9km.tif')\n",
        "\n",
        "  im_width=dataset12.RasterXSize\n",
        "  im_height=dataset12.RasterYSize\n",
        "  print(im_width)\n",
        "  print(im_height)\n",
        "  im_geotrans=dataset12.GetGeoTransform()\n",
        "  im_proj=dataset12.GetProjection()\n",
        "\n",
        "  Tb=dataset1.ReadAsArray(0,0,im_width,im_height).reshape(-1,1)\n",
        "  LST=dataset2.ReadAsArray(0,0,im_width,im_height).reshape(-1,1)*0.02\n",
        "  NDVI=dataset3.ReadAsArray(0,0,im_width,im_height).reshape(-1,1)\n",
        "  NDWI=dataset4.ReadAsArray(0,0,im_width,im_height).reshape(-1,1)\n",
        "  EVI=dataset5.ReadAsArray(0,0,im_width,im_height).reshape(-1,1)\n",
        "  Grass=(dataset6.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "  Bare=(dataset7.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "  Crops=(dataset8.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "  Shrub=(dataset9.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "  Tree=(dataset10.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "  Clay=(dataset11.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "  Sand=(dataset12.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "  Bulk=(dataset13.ReadAsArray(0,0,im_width,im_height)/100).reshape(-1,1)\n",
        "\n",
        "  del dataset1,dataset2,dataset3,dataset4,dataset5,dataset6,dataset7\n",
        "  del dataset8,dataset9,dataset10,dataset11,dataset12,dataset13\n",
        "\n",
        "  Tb[np.isnan(Tb)]=300\n",
        "  LST[np.isnan(LST)]=300\n",
        "  NDVI[np.isnan(NDVI)]=0\n",
        "  NDWI[np.isnan(NDWI)]=0\n",
        "  EVI[np.isnan(EVI)]=0\n",
        "  Grass[np.isnan(Grass)]=0\n",
        "  Bare[np.isnan(Bare)]=0\n",
        "  Crops[np.isnan(Crops)]=0\n",
        "  Shrub[np.isnan(Shrub)]=0\n",
        "  Tree[np.isnan(Tree)]=0\n",
        "  Clay[np.isnan(Clay)]=0\n",
        "  Sand[np.isnan(Sand)]=0\n",
        "  Bulk[np.isnan(Bulk)]=0\n",
        "\n",
        "###########################################################################################################################################\n",
        "\n",
        "  model_w = Net(8,10,1)   #5 10 1\n",
        "  model_tau = Net(8,10,1)   #8 10 1\n",
        "  model_SM = Net(4,5,1)   #10 10 1\n",
        "\n",
        "  #模型加载\n",
        "  model_w.load_state_dict(torch.load(str('/content/drive/My Drive/model_w_global3.pth'),weights_only=True))\n",
        "  model_tau.load_state_dict(torch.load(str('/content/drive/My Drive/model_tau_global3.pth'),weights_only=True))\n",
        "  model_SM.load_state_dict(torch.load(str('/content/drive/My Drive/model_SM_global3.pth'),weights_only=True))\n",
        "  model_w.eval();model_tau.eval();model_SM.eval()\n",
        "\n",
        "  Tb1 = torch.Tensor(Tb)\n",
        "  LST1 = torch.Tensor(LST)\n",
        "  sta = torch.cat([torch.Tensor(NDVI), torch.Tensor(NDWI), torch.Tensor(EVI), torch.Tensor(Grass), torch.Tensor(Bare), torch.Tensor(Crops), torch.Tensor(Shrub), torch.Tensor(Tree)], dim=1)\n",
        "  dyn = torch.cat([torch.Tensor(NDVI), torch.Tensor(NDWI), torch.Tensor(EVI), torch.Tensor(Grass), torch.Tensor(Bare), torch.Tensor(Crops), torch.Tensor(Shrub), torch.Tensor(Tree)], dim=1)\n",
        "  dic = torch.cat([torch.Tensor(Clay), torch.Tensor(Sand), torch.Tensor(Bulk)], dim=1)\n",
        "\n",
        "  del Tb,LST,NDWI,EVI,Grass,Bare,Crops,Shrub,Tree,Clay,Bulk\n",
        "\n",
        "  tau = model_tau(dyn)\n",
        "  w = model_w(sta)\n",
        "  del sta,dyn\n",
        "  del model_w,model_tau\n",
        "  torch.cuda.empty_cache()\n",
        "  input_test = SCA(w, tau, Tb1, LST1, dic)\n",
        "  del w,tau,Tb1,LST1,dic\n",
        "  SM_test = model_SM(input_test)\n",
        "  del input_test\n",
        "  del model_SM\n",
        "  torch.cuda.empty_cache()\n",
        "  SM = SM_test.detach().numpy()\n",
        "\n",
        "\n",
        "  SM = np.array(SM)*6/5\n",
        "  for h in range(0,im_width*im_height):\n",
        "    if NDVI[h] <= 0 or Sand[h] == 0:\n",
        "      SM[h,0]=0\n",
        "  SM = SM.reshape(im_height,im_width)\n",
        "  SM = np.array(SM, dtype=np.float32)\n",
        "\n",
        "\n",
        "  ##Array转Tif\n",
        "\n",
        "  driver=gdal.GetDriverByName('GTiff')\n",
        "  datasetnew=driver.Create('/content/drive/My Drive/GlobalSMImg10_3.tif',im_width,im_height,1,gdal.GDT_Float32)\n",
        "  datasetnew.SetGeoTransform(im_geotrans)\n",
        "  datasetnew.SetProjection(im_proj)\n",
        "  band=datasetnew.GetRasterBand(1)\n",
        "  band.WriteArray(SM)\n",
        "  datasetnew.FlushCache()\n",
        "  del datasetnew"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOglYyyBcr9LWzv/rOCsSuA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}